{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codenames_0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPXTUuKyg5DXOcgpKZ8kwii",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shikha-aggarwal/nlp_games/blob/main/codenames_wordnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaXYrVAfTuR4"
      },
      "source": [
        "#An implementation of the board game Codenames.\n",
        "https://en.wikipedia.org/wiki/Codenames_(board_game)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eralVpZo0c8J"
      },
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLVTvlottqPP",
        "outputId": "9bb5fb41-2531-4662-e77f-e2b52c37be4b"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import collections\n",
        "import random\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import words"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbpfRXUct5s6",
        "outputId": "939febc9-e2ae-4db7-ee0b-cee51ba23789"
      },
      "source": [
        "# The first time you run this will download a ~862MB file\n",
        "glove = torchtext.vocab.GloVe(name=\"6B\", dim=100)\n",
        "porter_stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "wordlist = words.words()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:52, 2.09MB/s]                          \n",
            "100%|█████████▉| 398103/400000 [00:19<00:00, 19788.42it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwFcI31x-2nw",
        "outputId": "210edac9-fb3a-45bc-c338-6e7990320276"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PikS5vJ00jal"
      },
      "source": [
        "## 2. Get a set of game-sy words to construct the game. Using just nouns for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX_ebDhaLoMl",
        "outputId": "6482a26f-1994-4780-e596-23e1d6a38b9b"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Colab Notebooks/Codewords/data/'\n",
        "glove_vocab_file = data_dir + 'vocab.txt'\n",
        "\n",
        "## Save the vocab file only once\n",
        "# def save_glove_vocab(path):\n",
        "#   with open(path, 'w+') as f:     \n",
        "#     for token, index in glove.stoi.items():\n",
        "#       f.write(f'{token}\\n')\n",
        "# save_glove_vocab(glove_vocab_file)\n",
        "\n",
        "def read_glove_vocab(path):\n",
        "    vocab = []\n",
        "    i = 0\n",
        "    with open(path, 'r') as f:\n",
        "      for line in f:\n",
        "        token = line.strip()\n",
        "        vocab.append(token)\n",
        "    return vocab\n",
        "\n",
        "all_glove_words = read_glove_vocab(glove_vocab_file)\n",
        "\n",
        "## Get common-use English words. \n",
        "## Source: https://github.com/first20hours/google-10000-english\n",
        "english_word_files = ['english_10k_long.txt',\n",
        "                      'english_10k_medium.txt']\n",
        "\n",
        "common_use_words = []\n",
        "\n",
        "for filename in english_word_files:\n",
        "  with open(data_dir + filename, \"r\") as file:\n",
        "    for line in file:\n",
        "      word = line.strip()\n",
        "      if word in all_glove_words:\n",
        "        common_use_words.append(word)\n",
        "\n",
        "# Get nouns from wordnet\n",
        "nouns = {x.name().split('.', 1)[0] for x in wn.all_synsets('n')} \n",
        "\n",
        "common_nouns = [w for w in common_use_words if w in nouns]\n",
        "\n",
        "# shuffle the words\n",
        "random.shuffle(common_nouns)\n",
        "print(\"Number of words in our game set: \", len(common_nouns))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in our game set:  3714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIXRJPzI1zrv"
      },
      "source": [
        "## 3. Util functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvC4Vr7LBzwp",
        "outputId": "22838f5c-3d6a-4a3e-d77c-789c4e0b3534"
      },
      "source": [
        "def get_nearest_words(word_vector, n = 5):\n",
        "  \"\"\"\n",
        "  Returns the nearest words in the Glove vector space.\n",
        "\n",
        "  :param word_vector: Glove word vector of the word of type torch.Tensor\n",
        "  :returns: List of tuples (word, distance) in ascending order of distance\n",
        "  \"\"\"\n",
        "  \n",
        "  distance_to_all = torch.norm(glove.vectors - word_vector, dim=1)\n",
        "  dist_sorted = sorted(enumerate(distance_to_all.numpy()), key=lambda x: x[1])\n",
        "  nearest_word_list = []\n",
        "\n",
        "  for index, distance in dist_sorted:\n",
        "    word = glove.itos[index]\n",
        "    if word not in stop_words and word in wordlist:\n",
        "      nearest_word_list.append((word, distance))\n",
        "    if len(nearest_word_list) == n:\n",
        "      break\n",
        "\n",
        "  return nearest_word_list\n",
        "\n",
        "\n",
        "nearest_word_example = get_nearest_words(glove['doctor'] - glove['man'] + glove['woman'])\n",
        "print(\"nearest words to 'doctor - man + woman': \\n\", nearest_word_example)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nearest words to 'doctor - man + woman': \n",
            " [('doctor', 3.3640678), ('nurse', 4.2283154), ('physician', 4.7054324), ('woman', 4.8734255), ('dentist', 4.969891)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdhiKWsLGtTG",
        "outputId": "20b8d04c-3e6e-40ac-f364-99495d65c51e"
      },
      "source": [
        "def nearest_valid_suggestion(word_group, nearest_words, distance_threshold):\n",
        "  \"\"\"\n",
        "  Filters out words in nearest_words with same root as any of the words in \n",
        "  word_group or more than distance_threshold away.\n",
        "\n",
        "  :param word_group: List of words - fixed points.\n",
        "  :param nearest_words: List of potential points nearby sorted by distance\n",
        "  :param distance_threshold: max distance possible a group word and nearest_word\n",
        "  :returns: nearest_valid_word, distance\n",
        "  \"\"\"\n",
        "  for word, distance in nearest_words:\n",
        "    invalid = False\n",
        "    for w in word_group:\n",
        "      if word in stop_words:\n",
        "        invalid = True\n",
        "      if porter_stemmer.stem(word) == porter_stemmer.stem(w):\n",
        "        invalid = True\n",
        "      if torch.norm(glove[w] - glove[word]) > distance_threshold:\n",
        "        invalid = True\n",
        "\n",
        "    if not invalid:\n",
        "      return word, distance\n",
        "\n",
        "  return None, None\n",
        "\n",
        "\n",
        "def get_clue_word_from_mean(word_list, words_covered = 1, distance_threshold = 4):\n",
        "  \"\"\"\n",
        "  Gets the possible clue words for groups of words_covered number of words\n",
        "  by finding the closest word to the mean of word vectors.\n",
        "\n",
        "  :param word_list: list of words that we need to find clue for.\n",
        "  :param words_covered: number of words we want to try finding the clue for.\n",
        "  :param distance_threshold: max distance possible between clue word and word\n",
        "  :returns: List of tuples (word_group, (word, dist)) in ascending order of dist\n",
        "  \"\"\"\n",
        "  num_words = len(word_list)\n",
        "  distances = {}\n",
        "\n",
        "  nearest_word_list = []\n",
        "\n",
        "  for combination in combinations(word_list, words_covered):\n",
        "    sum_tensor = torch.zeros(glove[word_list[0]].shape)\n",
        "    for w in combination:\n",
        "      sum_tensor += glove[w]\n",
        "    mean_word_vec = sum_tensor/(words_covered * 1.0)\n",
        "    nearest_words = get_nearest_words(mean_word_vec, n = 20)\n",
        "    nearest_valid_word, dist = nearest_valid_suggestion(combination, nearest_words, \n",
        "                                                  distance_threshold)\n",
        "    if nearest_valid_word is not None:\n",
        "      nearest_word_list.append((combination, (nearest_valid_word, dist)))\n",
        "\n",
        "  ## sort according to distance\n",
        "  nearest_word_list = sorted(nearest_word_list, key=lambda x: x[1][1])\n",
        "\n",
        "  return nearest_word_list\n",
        "\n",
        "\n",
        "clues = get_clue_word_from_mean(['doctor', 'man', 'woman', 'grandmother', 'mother', 'king'])\n",
        "print('Possible clues for single words: \\n')\n",
        "for (word, (clue, distance)) in clues:\n",
        "  print(word[0], ' --> ', clue, distance)\n",
        "\n",
        "\n",
        "def get_nearest_word_from_list(word, word_list, n = 5, distance_threshold = 6):\n",
        "  \"\"\"\n",
        "  Returns the nearest word in the word_list.\n",
        "\n",
        "  :param word: string\n",
        "  :param word_list: List of reference words\n",
        "  :returns: nearest word from the list\n",
        "  \"\"\"\n",
        "  zero_tensor = torch.zeros(glove['cat'].shape)\n",
        "\n",
        "  valid_word_list = []\n",
        "  word_list_vectors = []\n",
        "  for w in word_list:\n",
        "    if not torch.all(torch.eq(zero_tensor, glove[w])):\n",
        "      word_list_vectors.append(glove[w])\n",
        "      valid_word_list.append(w)\n",
        "\n",
        "  if len(word_list_vectors) < 1:\n",
        "    return []\n",
        "    \n",
        "  word_list_tensor = torch.stack(word_list_vectors)\n",
        "  \n",
        "  word_vector = glove[word]\n",
        "  distance_to_all = torch.norm(word_list_tensor - word_vector, dim=1)\n",
        "  dist_sorted = sorted(enumerate(distance_to_all.numpy()), key=lambda x: x[1])\n",
        "  nearest_word_list = []\n",
        "\n",
        "  for index, distance in dist_sorted:\n",
        "    invalid = False\n",
        "    cmp_word = valid_word_list[index]\n",
        "    # print(cmp_word, distance)\n",
        "    if cmp_word in stop_words:\n",
        "        invalid = True\n",
        "    if porter_stemmer.stem(word) == porter_stemmer.stem(cmp_word):\n",
        "        invalid = True\n",
        "    if torch.norm(glove[cmp_word] - glove[word]) > distance_threshold:\n",
        "        invalid = True\n",
        "    \n",
        "    if not invalid:\n",
        "      nearest_word_list.append(cmp_word)\n",
        "\n",
        "    if len(nearest_word_list) == n:\n",
        "      break\n",
        "\n",
        "  return nearest_word_list\n",
        "\n",
        "print(\"--------\")\n",
        "print(get_nearest_word_from_list('bun', ['food', 'bread', 'scooter'], n = 5))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Possible clues for single words: \n",
            "\n",
            "grandmother  -->  aunt 2.2975805\n",
            "mother  -->  daughter 2.6008523\n",
            "woman  -->  girl 3.2580621\n",
            "man  -->  woman 3.3640678\n",
            "doctor  -->  physician 3.6094282\n",
            "--------\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylzFIrRIAElP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Zmx-VrrQwX"
      },
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "def get_lemmas(word):\n",
        "  list_ret = []\n",
        "  for synset in wn.synsets(word):\n",
        "    list_ret.extend(synset.lemma_names())\n",
        "  print(list_ret)\n",
        "  return list_ret\n",
        "\n",
        "def get_clue_word_from_intersection(word_list, words_covered = 1, distance_threshold = 4):\n",
        "  \"\"\"\n",
        "  Gets the possible clue words for groups of words_covered number of words\n",
        "  by finding words in intersection of the nearest words.\n",
        "\n",
        "  :param word_list: list of words that we need to find clue for.\n",
        "  :param words_covered: number of words we want to try finding the clue for.\n",
        "  :param distance_threshold: max distance possible between clue word and word\n",
        "  :returns: List of tuples (word_group, (word, dist)) in ascending order of dist\n",
        "  \"\"\"\n",
        "  num_words = len(word_list)\n",
        "  distances = {}\n",
        "\n",
        "  for combination in combinations(word_list, words_covered):\n",
        "    intersection_set = set(get_lemmas(combination[0]))\n",
        "    for w in combination[1:]:\n",
        "      intersection_set = intersection_set.intersection(get_lemmas(w))\n",
        "\n",
        "  return list(intersection_set)\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "GyCgaRJd2IAy",
        "outputId": "9f75eb3a-d84d-49c7-bf6c-4a747f125951"
      },
      "source": [
        "# lowest_common_hypernyms\n",
        "\n",
        "def get_something_awesome_with_hypernym(word_list, words_covered = 2, distance_threshold = 4):\n",
        "  \"\"\"\n",
        "  Gets the possible clue words for groups of words_covered number of words\n",
        "  by finding the lowest common hypernym between two synsets: \n",
        "\n",
        "  :param word_list: list of words that we need to find clue for.\n",
        "  :param words_covered: number of words we want to try finding the clue for.\n",
        "  :param distance_threshold: max distance possible between clue word and word\n",
        "  :returns: List of tuples (word_group, (word, dist)) in ascending order of dist\n",
        "  \"\"\"\n",
        "  num_words = len(word_list)\n",
        "  distances = {}\n",
        "\n",
        "  synset_1 = wn.synsets(word_list[0])[0]\n",
        "  synset_2 = wn.synsets(word_list[1])[0]\n",
        "  paths = synset_1._shortest_hypernym_paths(synset_2)\n",
        "  paths = {k:v for k,v in paths.items() if v > 0}\n",
        "  common_hypernym = min(paths, key=paths.get)\n",
        "  # possible_clues = synset_1.closure(common_hypernym.hyponyms())\n",
        "  # print(list(possible_clues))\n",
        "  possible_clues = list(min(paths, key=paths.get).closure(lambda s:s.hyponyms()))\n",
        "\n",
        "  return_dict = {}\n",
        "  for synset in possible_clues:\n",
        "    for lemma in synset.lemmas():\n",
        "      if lemma.name() in all_glove_words:\n",
        "        return_dict[lemma.name()] = lemma.count()\n",
        "\n",
        "  set_1 = set(get_nearest_word_from_list(word_list[0], list(return_dict.keys()), n = 30))\n",
        "  set_2 = set(get_nearest_word_from_list(word_list[1], list(return_dict.keys()), n = 30))\n",
        "  closest_word_list = list(set_1.intersection(set_2))\n",
        "  \n",
        "  count_sorted = sorted(closest_word_list, key=lambda x: return_dict[x], reverse=True)\n",
        "\n",
        "  print(count_sorted)\n",
        "  if len(count_sorted) > 0:\n",
        "    return count_sorted[0]\n",
        "  return []\n",
        "\n",
        "print(\"testing function get_something_awesome_with_hypernym with words: ['motorcar', 'bike']\")\n",
        "get_something_awesome_with_hypernym(['motorcar', 'bike'], 2)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing function get_something_awesome_with_hypernym with words: ['motorcar', 'bike']\n",
            "['minibike', 'tractor', 'go-kart', 'cab', 'jalopy', 'limo', 'limousine', 'saloon', 'scrambler', 'motorbike', 'moped', 'taxicab', 'minivan', 'snowplow', 'lorry']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'minibike'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpSxZjzvkgnA"
      },
      "source": [
        "def get_awesome_for_groups(word_list, word_count = 2):\n",
        "  matching_word = {}\n",
        "  for combination in combinations(word_list, word_count):\n",
        "    matching_word[combination] = get_something_awesome_with_hypernym(combination)\n",
        "  return matching_word"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9GzkLh_EHYz"
      },
      "source": [
        "## 4. Start a Codewords game"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQdIvfUlDzti"
      },
      "source": [
        "## Select words for the game\n",
        "\n",
        "grid_len = 5\n",
        "grid_height = 5\n",
        "num_words_in_game = grid_len * grid_height\n",
        "word_set = random.sample(common_nouns, num_words_in_game)\n",
        "\n",
        "## Divide into red, blue, and neutral\n",
        "one_third = int(num_words_in_game / 3)\n",
        "red_words = random.sample(word_set, one_third)\n",
        "remaining_words = [item for item in word_set if item not in red_words]\n",
        "blue_words = random.sample(remaining_words, one_third)\n",
        "neutral_words = [item for item in remaining_words if item not in blue_words]"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3g_WlxUGHUX"
      },
      "source": [
        "def print_clue_words(words, clues):\n",
        "  print('Words: ', words, '\\n')\n",
        "  print('Possible clues:')\n",
        "  for (word, (clue, distance)) in clues:\n",
        "    print(word[0], ' -- ', clue, distance)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-o358YQFUYz",
        "outputId": "66303f9c-d257-4c58-a7c4-39e94d5beea8"
      },
      "source": [
        "clues = get_clue_word_from_mean(red_words)\n",
        "print_clue_words(red_words, clues)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words:  ['television', 'brisbane', 'smell', 'school', 'lodging', 'diary', 'chain', 'karaoke'] \n",
            "\n",
            "Possible clues:\n",
            "school  --  college 3.1588404\n",
            "television  --  broadcast 3.2479038\n",
            "smell  --  odor 3.2587109\n",
            "brisbane  --  wellington 3.737849\n",
            "lodging  --  accommodation 3.8979847\n",
            "chain  --  supermarket 3.9276807\n",
            "diary  --  memoir 3.9922433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXmkC50nBB28",
        "outputId": "98652ae0-57e2-4fdb-8d3e-fd7c4270b3fe"
      },
      "source": [
        "clues = get_clue_word_from_mean(red_words, words_covered = 2)\n",
        "print_clue_words(red_words, clues)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words:  ['television', 'brisbane', 'smell', 'school', 'lodging', 'diary', 'chain', 'karaoke'] \n",
            "\n",
            "Possible clues:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LyTw-RKFl4i",
        "outputId": "9fbdf9e6-4812-4220-9a76-e993d50eae2f"
      },
      "source": [
        "clues = get_clue_word_from_mean(blue_words)\n",
        "print_clue_words(blue_words, clues)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words:  ['basis', 'calculation', 'remark', 'michigan', 'apartment', 'bristol', 'armor', 'contributor'] \n",
            "\n",
            "Possible clues:\n",
            "calculation  --  estimation 3.2174172\n",
            "remark  --  suggestion 3.4864097\n",
            "apartment  --  bedroom 3.5394855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhvjEj7ZFx4Q"
      },
      "source": [
        "clue_pairs = get_awesome_for_groups(red_words, word_count = 2)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvYfJJFClkMn",
        "outputId": "ba7ded69-3f50-4ebf-9552-91037fb6c87a"
      },
      "source": [
        "for k, v in clue_pairs.items():\n",
        "  print(k, \" : \", v)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('television', 'brisbane')  :  []\n",
            "('television', 'smell')  :  []\n",
            "('television', 'school')  :  []\n",
            "('television', 'lodging')  :  []\n",
            "('television', 'diary')  :  []\n",
            "('television', 'chain')  :  cable\n",
            "('television', 'karaoke')  :  []\n",
            "('brisbane', 'smell')  :  []\n",
            "('brisbane', 'school')  :  []\n",
            "('brisbane', 'lodging')  :  []\n",
            "('brisbane', 'diary')  :  []\n",
            "('brisbane', 'chain')  :  []\n",
            "('brisbane', 'karaoke')  :  []\n",
            "('smell', 'school')  :  []\n",
            "('smell', 'lodging')  :  []\n",
            "('smell', 'diary')  :  []\n",
            "('smell', 'chain')  :  []\n",
            "('smell', 'karaoke')  :  []\n",
            "('school', 'lodging')  :  []\n",
            "('school', 'diary')  :  []\n",
            "('school', 'chain')  :  []\n",
            "('school', 'karaoke')  :  []\n",
            "('lodging', 'diary')  :  guestroom\n",
            "('lodging', 'chain')  :  restaurant\n",
            "('lodging', 'karaoke')  :  diner\n",
            "('diary', 'chain')  :  []\n",
            "('diary', 'karaoke')  :  []\n",
            "('chain', 'karaoke')  :  []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhIyJMBMmzIJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}