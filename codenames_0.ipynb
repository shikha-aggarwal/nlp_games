{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codenames_0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjzSE+C9IwesqebY/S+fiS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shikha-aggarwal/nlp_games/blob/main/codenames_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaXYrVAfTuR4"
      },
      "source": [
        "#An implementation of the board game Codenames.\n",
        "https://en.wikipedia.org/wiki/Codenames_(board_game)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eralVpZo0c8J"
      },
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLVTvlottqPP",
        "outputId": "a0bb0ddc-7d17-42fe-d610-d51e700172fc"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import collections\n",
        "import random\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import words"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbpfRXUct5s6"
      },
      "source": [
        "# The first time you run this will download a ~823MB file\n",
        "glove = torchtext.vocab.GloVe(name=\"6B\", dim=100)\n",
        "porter_stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "wordlist = words.words()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwFcI31x-2nw",
        "outputId": "2c6281ab-a24a-44fa-9c8c-733c9ef66754"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PikS5vJ00jal"
      },
      "source": [
        "## 2. Get a set of game-sy words to construct the game. Using just nouns for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX_ebDhaLoMl",
        "outputId": "321b34fd-9e77-4a4c-dbc4-b53faeae478c"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Colab Notebooks/Codewords/data/'\n",
        "glove_vocab_file = data_dir + 'vocab.txt'\n",
        "\n",
        "## Save the vocab file only once\n",
        "# def save_glove_vocab(path):\n",
        "#   with open(path, 'w+') as f:     \n",
        "#     for token, index in glove.stoi.items():\n",
        "#       f.write(f'{token}\\n')\n",
        "# save_glove_vocab(glove_vocab_file)\n",
        "\n",
        "def read_glove_vocab(path):\n",
        "    vocab = []\n",
        "    i = 0\n",
        "    with open(path, 'r') as f:\n",
        "      for line in f:\n",
        "        token = line.strip()\n",
        "        vocab.append(token)\n",
        "    return vocab\n",
        "\n",
        "all_glove_words = read_glove_vocab(glove_vocab_file)\n",
        "\n",
        "## Get common-use English words. \n",
        "## Source: https://github.com/first20hours/google-10000-english\n",
        "english_word_files = ['english_10k_long.txt',\n",
        "                      'english_10k_medium.txt']\n",
        "\n",
        "common_use_words = []\n",
        "\n",
        "for filename in english_word_files:\n",
        "  with open(data_dir + filename, \"r\") as file:\n",
        "    for line in file:\n",
        "      word = line.strip()\n",
        "      if word in all_glove_words:\n",
        "        common_use_words.append(word)\n",
        "\n",
        "# Get nouns from wordnet\n",
        "nouns = {x.name().split('.', 1)[0] for x in wn.all_synsets('n')} \n",
        "\n",
        "common_nouns = [w for w in common_use_words if w in nouns]\n",
        "\n",
        "# shuffle the words\n",
        "random.shuffle(common_nouns)\n",
        "print(len(common_nouns))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIXRJPzI1zrv"
      },
      "source": [
        "## 3. Util functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvC4Vr7LBzwp",
        "outputId": "f874629a-ed78-4757-fd6c-71efee4fa4ba"
      },
      "source": [
        "def get_nearest_words(word_vector, n = 5):\n",
        "  \"\"\"\n",
        "  Returns the nearest words in the Glove vector space.\n",
        "\n",
        "  :param word_vector: Glove word vector of the word of type torch.Tensor\n",
        "  :returns: List of tuples (word, distance) in ascending order of distance\n",
        "  \"\"\"\n",
        "  \n",
        "  distance_to_all = torch.norm(glove.vectors - word_vector, dim=1)\n",
        "  dist_sorted = sorted(enumerate(distance_to_all.numpy()), key=lambda x: x[1])\n",
        "  nearest_word_list = []\n",
        "\n",
        "  for index, distance in dist_sorted:\n",
        "    word = glove.itos[index]\n",
        "    if word not in stop_words and word in wordlist:\n",
        "      nearest_word_list.append((word, distance))\n",
        "    if len(nearest_word_list) == n:\n",
        "      break\n",
        "\n",
        "  return nearest_word_list\n",
        "\n",
        "  \n",
        "get_nearest_words(glove['doctor'] - glove['man'] + glove['woman'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('doctor', 3.3640678),\n",
              " ('nurse', 4.2283154),\n",
              " ('physician', 4.7054324),\n",
              " ('woman', 4.8734255),\n",
              " ('dentist', 4.969891)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdhiKWsLGtTG",
        "outputId": "58901f6e-eefc-4241-d5a5-3e348a70ee2c"
      },
      "source": [
        "def nearest_valid_suggestion(word_group, nearest_words, distance_threshold):\n",
        "  \"\"\"\n",
        "  Filters out words in nearest_words with same root as any of the words in \n",
        "  word_group or more than distance_threshold away.\n",
        "\n",
        "  :param word_group: List of words - fixed points.\n",
        "  :param nearest_words: List of potential points nearby sorted by distance\n",
        "  :param distance_threshold: max distance possible a group word and nearest_word\n",
        "  :returns: nearest_valid_word, distance\n",
        "  \"\"\"\n",
        "  for word, distance in nearest_words:\n",
        "    invalid = False\n",
        "    for w in word_group:\n",
        "      if porter_stemmer.stem(word) == porter_stemmer.stem(w):\n",
        "        invalid = True\n",
        "      if torch.norm(glove[w] - glove[word]) > distance_threshold:\n",
        "        invalid = True\n",
        "\n",
        "    if not invalid:\n",
        "      return word, distance\n",
        "\n",
        "  return None, None\n",
        "\n",
        "\n",
        "def get_clue_word_from_mean(word_list, words_covered = 1, distance_threshold = 4):\n",
        "  \"\"\"\n",
        "  Gets the possible clue words for groups of words_covered number of words\n",
        "  by finding the closest word to the mean of word vectors.\n",
        "\n",
        "  :param word_list: list of words that we need to find clue for.\n",
        "  :param words_covered: number of words we want to try finding the clue for.\n",
        "  :param distance_threshold: max distance possible between clue word and word\n",
        "  :returns: List of tuples (word_group, (word, dist)) in ascending order of dist\n",
        "  \"\"\"\n",
        "  num_words = len(word_list)\n",
        "  distances = {}\n",
        "\n",
        "  nearest_word_list = []\n",
        "\n",
        "  for combination in combinations(word_list, words_covered):\n",
        "    sum_tensor = torch.zeros(glove[word_list[0]].shape)\n",
        "    for w in combination:\n",
        "      sum_tensor += glove[w]\n",
        "    mean_word_vec = sum_tensor/(words_covered * 1.0)\n",
        "    nearest_words = get_nearest_words(mean_word_vec, n = 20)\n",
        "    nearest_valid_word, dist = nearest_valid_suggestion(combination, nearest_words, \n",
        "                                                  distance_threshold)\n",
        "    if nearest_valid_word is not None:\n",
        "      nearest_word_list.append((combination, (nearest_valid_word, dist)))\n",
        "\n",
        "  ## sort according to distance\n",
        "  nearest_word_list = sorted(nearest_word_list, key=lambda x: x[1][1])\n",
        "\n",
        "  return nearest_word_list\n",
        "\n",
        "\n",
        "get_clue_word_from_mean(['doctor', 'man', 'woman', 'grandmother', 'mother', 'king'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('grandmother',), ('aunt', 2.2975805)),\n",
              " (('mother',), ('daughter', 2.6008523)),\n",
              " (('woman',), ('girl', 3.2580621)),\n",
              " (('man',), ('woman', 3.3640678)),\n",
              " (('doctor',), ('physician', 3.6094282))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9GzkLh_EHYz"
      },
      "source": [
        "## 4. Start a Codewords game"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQdIvfUlDzti"
      },
      "source": [
        "## Select words for the game\n",
        "\n",
        "grid_len = 5\n",
        "grid_height = 5\n",
        "num_words_in_game = grid_len * grid_height\n",
        "word_set = random.sample(common_nouns, num_words_in_game)\n",
        "\n",
        "## Divide into red, blue, and neutral\n",
        "one_third = int(num_words_in_game / 3)\n",
        "red_words = random.sample(word_set, one_third)\n",
        "remaining_words = [item for item in word_set if item not in red_words]\n",
        "blue_words = random.sample(remaining_words, one_third)\n",
        "neutral_words = [item for item in remaining_words if item not in blue_words]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-o358YQFUYz",
        "outputId": "e7229434-34dc-4a6b-de9d-d7af63f311ad"
      },
      "source": [
        "get_clue_word_from_mean(red_words)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('difficulty',), ('trouble', 3.360246))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXmkC50nBB28",
        "outputId": "d96ac49f-e25a-4eec-cf86-455678034c48"
      },
      "source": [
        "get_clue_word_from_mean(red_words, words_covered = 2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}