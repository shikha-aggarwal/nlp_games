{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codenames_0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMO7yKGlzxG3LDk9L8r1syQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shikha-aggarwal/nlp_games/blob/main/codenames_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaXYrVAfTuR4"
      },
      "source": [
        "#An implementation of the board game Codenames.\n",
        "https://en.wikipedia.org/wiki/Codenames_(board_game)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eralVpZo0c8J"
      },
      "source": [
        "## 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLVTvlottqPP",
        "outputId": "05dca09e-0774-4bbb-f503-62261fb0ef89"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import collections\n",
        "import random\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import words"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbpfRXUct5s6"
      },
      "source": [
        "# The first time you run this will download a ~823MB file\n",
        "glove = torchtext.vocab.GloVe(name=\"6B\", dim=100)\n",
        "porter_stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "wordlist = words.words()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwFcI31x-2nw",
        "outputId": "aaada579-9ca7-421f-ee4f-59f3b309e7a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PikS5vJ00jal"
      },
      "source": [
        "## 2. Get a set of game-sy words to construct the game. Using just nouns for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX_ebDhaLoMl",
        "outputId": "85fa21f8-d66e-4db1-b439-37d3a192e011"
      },
      "source": [
        "data_dir = '/content/drive/My Drive/Colab Notebooks/Codewords/data/'\n",
        "glove_vocab_file = data_dir + 'vocab.txt'\n",
        "\n",
        "## Save the vocab file only once\n",
        "# def save_glove_vocab(path):\n",
        "#   with open(path, 'w+') as f:     \n",
        "#     for token, index in glove.stoi.items():\n",
        "#       f.write(f'{token}\\n')\n",
        "# save_glove_vocab(glove_vocab_file)\n",
        "\n",
        "def read_glove_vocab(path):\n",
        "    vocab = []\n",
        "    i = 0\n",
        "    with open(path, 'r') as f:\n",
        "      for line in f:\n",
        "        token = line.strip()\n",
        "        vocab.append(token)\n",
        "    return vocab\n",
        "\n",
        "all_glove_words = read_glove_vocab(glove_vocab_file)\n",
        "\n",
        "## Get common-use English words. \n",
        "## Source: https://github.com/first20hours/google-10000-english\n",
        "english_word_files = ['english_10k_long.txt',\n",
        "                      'english_10k_medium.txt']\n",
        "\n",
        "common_use_words = []\n",
        "\n",
        "for filename in english_word_files:\n",
        "  with open(data_dir + filename, \"r\") as file:\n",
        "    for line in file:\n",
        "      word = line.strip()\n",
        "      if word in all_glove_words:\n",
        "        common_use_words.append(word)\n",
        "\n",
        "# Get nouns from wordnet\n",
        "nouns = {x.name().split('.', 1)[0] for x in wn.all_synsets('n')} \n",
        "\n",
        "common_nouns = [w for w in common_use_words if w in nouns]\n",
        "\n",
        "# shuffle the words\n",
        "random.shuffle(common_nouns)\n",
        "print(\"Number of words in our game set: \", len(common_nouns))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in our game set:  3714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIXRJPzI1zrv"
      },
      "source": [
        "## 3. Util functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvC4Vr7LBzwp",
        "outputId": "b8c7f58a-6402-483b-a0ba-fbdacce180c0"
      },
      "source": [
        "def get_nearest_words(word_vector, n = 5):\n",
        "  \"\"\"\n",
        "  Returns the nearest words in the Glove vector space.\n",
        "\n",
        "  :param word_vector: Glove word vector of the word of type torch.Tensor\n",
        "  :returns: List of tuples (word, distance) in ascending order of distance\n",
        "  \"\"\"\n",
        "  \n",
        "  distance_to_all = torch.norm(glove.vectors - word_vector, dim=1)\n",
        "  dist_sorted = sorted(enumerate(distance_to_all.numpy()), key=lambda x: x[1])\n",
        "  nearest_word_list = []\n",
        "\n",
        "  for index, distance in dist_sorted:\n",
        "    word = glove.itos[index]\n",
        "    if word not in stop_words and word in wordlist:\n",
        "      nearest_word_list.append((word, distance))\n",
        "    if len(nearest_word_list) == n:\n",
        "      break\n",
        "\n",
        "  return nearest_word_list\n",
        "\n",
        "\n",
        "nearest_word_example = get_nearest_words(glove['doctor'] - glove['man'] + glove['woman'])\n",
        "print(\"nearest words to 'doctor - man + woman': \\n\", nearest_word_example)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nearest words to 'doctor - man + woman': \n",
            " [('doctor', 3.3640678), ('nurse', 4.2283154), ('physician', 4.7054324), ('woman', 4.8734255), ('dentist', 4.969891)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdhiKWsLGtTG",
        "outputId": "57e156f1-dd24-4483-b6f2-7365416101bc"
      },
      "source": [
        "def nearest_valid_suggestion(word_group, nearest_words, distance_threshold):\n",
        "  \"\"\"\n",
        "  Filters out words in nearest_words with same root as any of the words in \n",
        "  word_group or more than distance_threshold away.\n",
        "\n",
        "  :param word_group: List of words - fixed points.\n",
        "  :param nearest_words: List of potential points nearby sorted by distance\n",
        "  :param distance_threshold: max distance possible a group word and nearest_word\n",
        "  :returns: nearest_valid_word, distance\n",
        "  \"\"\"\n",
        "  for word, distance in nearest_words:\n",
        "    invalid = False\n",
        "    for w in word_group:\n",
        "      if porter_stemmer.stem(word) == porter_stemmer.stem(w):\n",
        "        invalid = True\n",
        "      if torch.norm(glove[w] - glove[word]) > distance_threshold:\n",
        "        invalid = True\n",
        "\n",
        "    if not invalid:\n",
        "      return word, distance\n",
        "\n",
        "  return None, None\n",
        "\n",
        "\n",
        "def get_clue_word_from_mean(word_list, words_covered = 1, distance_threshold = 4):\n",
        "  \"\"\"\n",
        "  Gets the possible clue words for groups of words_covered number of words\n",
        "  by finding the closest word to the mean of word vectors.\n",
        "\n",
        "  :param word_list: list of words that we need to find clue for.\n",
        "  :param words_covered: number of words we want to try finding the clue for.\n",
        "  :param distance_threshold: max distance possible between clue word and word\n",
        "  :returns: List of tuples (word_group, (word, dist)) in ascending order of dist\n",
        "  \"\"\"\n",
        "  num_words = len(word_list)\n",
        "  distances = {}\n",
        "\n",
        "  nearest_word_list = []\n",
        "\n",
        "  for combination in combinations(word_list, words_covered):\n",
        "    sum_tensor = torch.zeros(glove[word_list[0]].shape)\n",
        "    for w in combination:\n",
        "      sum_tensor += glove[w]\n",
        "    mean_word_vec = sum_tensor/(words_covered * 1.0)\n",
        "    nearest_words = get_nearest_words(mean_word_vec, n = 20)\n",
        "    nearest_valid_word, dist = nearest_valid_suggestion(combination, nearest_words, \n",
        "                                                  distance_threshold)\n",
        "    if nearest_valid_word is not None:\n",
        "      nearest_word_list.append((combination, (nearest_valid_word, dist)))\n",
        "\n",
        "  ## sort according to distance\n",
        "  nearest_word_list = sorted(nearest_word_list, key=lambda x: x[1][1])\n",
        "\n",
        "  return nearest_word_list\n",
        "\n",
        "\n",
        "clues = get_clue_word_from_mean(['doctor', 'man', 'woman', 'grandmother', 'mother', 'king'])\n",
        "print('Possible clues for single words: \\n')\n",
        "for (word, (clue, distance)) in clues:\n",
        "  print(word[0], ' --> ', clue, distance)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Possible clues for single words: \n",
            "\n",
            "grandmother  -->  aunt 2.2975805\n",
            "mother  -->  daughter 2.6008523\n",
            "woman  -->  girl 3.2580621\n",
            "man  -->  woman 3.3640678\n",
            "doctor  -->  physician 3.6094282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9GzkLh_EHYz"
      },
      "source": [
        "## 4. Start a Codewords game"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQdIvfUlDzti"
      },
      "source": [
        "## Select words for the game\n",
        "\n",
        "grid_len = 5\n",
        "grid_height = 5\n",
        "num_words_in_game = grid_len * grid_height\n",
        "word_set = random.sample(common_nouns, num_words_in_game)\n",
        "\n",
        "## Divide into red, blue, and neutral\n",
        "one_third = int(num_words_in_game / 3)\n",
        "red_words = random.sample(word_set, one_third)\n",
        "remaining_words = [item for item in word_set if item not in red_words]\n",
        "blue_words = random.sample(remaining_words, one_third)\n",
        "neutral_words = [item for item in remaining_words if item not in blue_words]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3g_WlxUGHUX"
      },
      "source": [
        "def print_clue_words(words, clues):\n",
        "  print('Words: ', words, '\\n')\n",
        "  print('Possible clues:')\n",
        "  for (word, (clue, distance)) in clues:\n",
        "    print(word[0], ' -- ', clue, distance)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-o358YQFUYz",
        "outputId": "6fcd56e6-4014-44b3-cfbf-e459d7dcc236"
      },
      "source": [
        "clues = get_clue_word_from_mean(red_words)\n",
        "print_clue_words(red_words, clues)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words:  ['defendant', 'behavior', 'command', 'theorem', 'track', 'tobacco', 'updating', 'champagne'] \n",
            "\n",
            "Possible clues:\n",
            "behavior  --  behaviour 2.5661588\n",
            "defendant  --  plaintiff 3.3749182\n",
            "tobacco  --  cigarette 3.762019\n",
            "updating  --  recasting 3.9267678\n",
            "command  --  assigned 3.9655364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXmkC50nBB28",
        "outputId": "7813fb6b-c3f0-495f-c3d3-274339caeb51"
      },
      "source": [
        "clues = get_clue_word_from_mean(red_words, words_covered = 2)\n",
        "print_clue_words(red_words, clues)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words:  ['defendant', 'behavior', 'command', 'theorem', 'track', 'tobacco', 'updating', 'champagne'] \n",
            "\n",
            "Possible clues:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LyTw-RKFl4i",
        "outputId": "8db8848d-41d2-4f7f-eb36-2724bf219c53"
      },
      "source": [
        "clues = get_clue_word_from_mean(blue_words)\n",
        "print_clue_words(blue_words, clues)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words:  ['catalog', 'significance', 'figure', 'large', 'highlight', 'orleans', 'ancient', 'understanding'] \n",
            "\n",
            "Possible clues:\n",
            "large  --  small 2.1062658\n",
            "catalog  --  catalogue 2.3955834\n",
            "significance  --  importance 3.003083\n",
            "highlight  --  illustrate 3.5332692\n",
            "ancient  --  medieval 3.5792017\n",
            "understanding  --  knowledge 3.8240407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhvjEj7ZFx4Q"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}